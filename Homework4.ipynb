{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Python for Data Analysis, GMC, Vilnius University, 2025\n","\n","# HW4: Training a succesfull machine learning (ML) model\n","\n","- **Tasks in this homework are built around a single data file** which should be downloaded in the Notebook as asked in the cell after the imports.\n","- Packages allowed to be imported (but not necessarily needed): `scikit-learn`, `numpy`, `pandas`, `matplotlib`, `seaborn`, `tqdm`, `itertools`, `math`, `string`. Do not import any other packages.\n","- **You will need to upload your solutions into your Github repository** dedicated for the Python for Data Analysis course. Use the same repository used for Homework 3.\n","- Same requirements as for Homework 3:\n","   - Do not write docstrings (function description comments).\n","   - Keep prints informative.\n","   - Do not create classes.\n","   - Do not change assert statements.\n","\n","There are 5 tasks in this Notebook. They have slightly different numbers of points between them, with subpoints shown for each subtask e.g. (0.2p). You need to collect 8 points in total to get the maximum grade.\n","\n","As previously, each task consists of a text cell with task description, a code cell to solve the task, and a code cell with `assert` statements to check your code for *some* possible errors.\n","\n","Don't hesitate to contact me or Martynas if you are stuck."],"metadata":{"id":"HCbuDJ9YfLr9"}},{"cell_type":"code","source":["# your imports"],"metadata":{"id":"kbIq-GLMmFHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download the file using the link provided, by any method you like/understand the most,\n","# but the downloading process should happen inside the Notebook.\n","file_url = \"https://github.com/Tallivm/vu-python/blob/main/hw4_2025.csv\""],"metadata":{"id":"rMmLobkRc7Eg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_url = \"https://raw.githubusercontent.com/Tallivm/vu-python/main/hw4_2025.csv\"\n","\n","df = pd.read_csv(file_url)\n","\n","print(\"Loaded data shape:\", df.shape)\n","df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"LWG9V5yguKG0","executionInfo":{"status":"ok","timestamp":1765562427707,"user_tz":-120,"elapsed":436,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}},"outputId":"b3cc3e8a-3e03-43bd-c768-71e896868283"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded data shape: (2606, 8)\n"]},{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  snail_genus  leaf_width_mm  leaf_length_mm leaf_surface  \\\n","0           0    Spiralina           69.0           114.0        hairy   \n","1           1   Slimospira           51.0            34.0        hairy   \n","2           2  Mollisphora           47.0           114.0        hairy   \n","3           3     Flexorus           44.0            25.0       smooth   \n","4           4   Slimospira           12.0            68.0       smooth   \n","\n","   shell_height_mm shell_color  shell_radius_mm  \n","0              7.0     striped              5.0  \n","1              4.0      yellow              4.0  \n","2              6.0     striped              7.0  \n","3              5.0        dark              5.0  \n","4              5.0      yellow              5.0  "],"text/html":["\n","  <div id=\"df-92495774-37e6-4827-8b8d-f2bc91309a83\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>snail_genus</th>\n","      <th>leaf_width_mm</th>\n","      <th>leaf_length_mm</th>\n","      <th>leaf_surface</th>\n","      <th>shell_height_mm</th>\n","      <th>shell_color</th>\n","      <th>shell_radius_mm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Spiralina</td>\n","      <td>69.0</td>\n","      <td>114.0</td>\n","      <td>hairy</td>\n","      <td>7.0</td>\n","      <td>striped</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Slimospira</td>\n","      <td>51.0</td>\n","      <td>34.0</td>\n","      <td>hairy</td>\n","      <td>4.0</td>\n","      <td>yellow</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Mollisphora</td>\n","      <td>47.0</td>\n","      <td>114.0</td>\n","      <td>hairy</td>\n","      <td>6.0</td>\n","      <td>striped</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Flexorus</td>\n","      <td>44.0</td>\n","      <td>25.0</td>\n","      <td>smooth</td>\n","      <td>5.0</td>\n","      <td>dark</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Slimospira</td>\n","      <td>12.0</td>\n","      <td>68.0</td>\n","      <td>smooth</td>\n","      <td>5.0</td>\n","      <td>yellow</td>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92495774-37e6-4827-8b8d-f2bc91309a83')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-92495774-37e6-4827-8b8d-f2bc91309a83 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-92495774-37e6-4827-8b8d-f2bc91309a83');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-13e0da7f-bf97-4cef-bf6d-e2af195e0db6\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13e0da7f-bf97-4cef-bf6d-e2af195e0db6')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-13e0da7f-bf97-4cef-bf6d-e2af195e0db6 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2606,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 752,\n        \"min\": 0,\n        \"max\": 2605,\n        \"num_unique_values\": 2606,\n        \"samples\": [\n          782,\n          786,\n          602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snail_genus\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Spiralina\",\n          \"Slimospira\",\n          \"Caracolus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leaf_width_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.315501812885092,\n        \"min\": 1.0,\n        \"max\": 83.0,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          13.0,\n          69.0,\n          25.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leaf_length_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.29671512707957,\n        \"min\": 2.0,\n        \"max\": 133.0,\n        \"num_unique_values\": 129,\n        \"samples\": [\n          65.0,\n          79.0,\n          123.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leaf_surface\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hairy\",\n          \"smooth\",\n          \"waxy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shell_height_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.221222732577564,\n        \"min\": -9.0,\n        \"max\": 12.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1.0,\n          3.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shell_color\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"yellow\",\n          \"brown\",\n          \"dark\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shell_radius_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2972095596523463,\n        \"min\": -7.0,\n        \"max\": 13.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          3.0,\n          13.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Run this cell to store the name of the column to predict.\n","# Use this variable when needed.\n","TO_PREDICT = 'snail_genus'"],"metadata":{"id":"fb2_t1bcmGLS","executionInfo":{"status":"ok","timestamp":1765562732243,"user_tz":-120,"elapsed":41,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# üçÇ Task 1 (1 point): The new challenge"],"metadata":{"id":"Bf-MilLshM9i"}},{"cell_type":"markdown","source":["Some researchers who collected data for SNAILAB complained that measuring a single sample takes a lot of time and is quite difficult. Many snails are actually found on fallen leaves, not on whole plants, making several measurements impossible to make. Moreover, if a snail hides inside its shell, for certain measurements the researcher is forced to wait until the snail fully appears again.\n","\n","An intern from SNAILAB suggested that they could use AI to solve this issue. After several discussions, they decided to train a model which would **predict the genus of a snail** from only easy-to-measure features. The intern prepared some useful data but then got sick. So, SNAILAB asks for your help once more.\n","\n","You will need to train several simple models to predict snail genus for a provided data set, and select the best model.\n","\n","But first - the provided **data should be explored**!\n","\n","1. (0.2p) Load the data as a DataFrame, name it `raw`. Make sure the \"Unnamed: 0\" column is not formed by providing correct parameters into the `read_csv()` function. Print out a short report (in any format you like, make it a function) using f-strings and containing this information:\n","   - Number of NaN values in total, and if there are NaNs, then in which columns and how many;\n","   - Min, mean, and max values of each numeric column;\n","   - Unique values and their counts of each categorical column.\n","\n","2. (0.4p) According to the report, make certain changes to the data and name the result `clean`:\n","   - If there are NaNs, remove full rows with them;\n","   - Remove full rows containing seemingly incorrect measurement values (e.g. negative values for length measurements).\n","   - Even if these steps were not required for this data, do it nevertheless, in a way that could be applicable to any dataset with such requirements (but maybe different columns and values).\n","\n","3. (0.1p) Print out the report again using the previously written function.\n","\n","4. (0.3p) Obtain and visualize a Spearman correlation matrix (as a heatmap) for all numeric columns. Make sure colormap is used correctly (divergent, zero in the middle), and the plot contains column names."],"metadata":{"id":"iebEKf1zgG86"}},{"cell_type":"code","source":["def data_report(df):\n","    print(f\"DATA REPORT (rows={df.shape[0]}, columns={df.shape[1]})\\n\")\n","\n","    # NaN report\n","    total_nans = df.isna().sum().sum()\n","    print(f\"Total NaN values: {total_nans}\")\n","    if total_nans > 0:\n","        print(\"NaNs per column:\")\n","        print(df.isna().sum()[df.isna().sum() > 0])\n","    print()\n","\n","    # Numeric columns stats\n","    numeric_cols = df.select_dtypes(include=[np.number]).columns\n","    print(\"Numeric columns summary:\")\n","    for col in numeric_cols:\n","        print(\n","            f\"{col}: min={df[col].min():.2f}, \"\n","            f\"mean={df[col].mean():.2f}, \"\n","            f\"max={df[col].max():.2f}\"\n","        )\n","    print()\n","\n","    # Categorical columns\n","    categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n","    print(\"Categorical columns value counts:\")\n","    for col in categorical_cols:\n","        print(f\"\\n{col}:\")\n","        print(df[col].value_counts())\n","\n","data_report(raw)\n","\n","clean = raw.copy()\n","\n","# 1. Drop rows with any NaNs\n","clean = clean.dropna()\n","\n","# 2. Remove rows with invalid numeric values (negative or zero where impossible)\n","numeric_cols = clean.select_dtypes(include=[np.number]).columns\n","\n","for col in numeric_cols:\n","    clean = clean[clean[col] >= 0]\n","\n","print(\"Clean data shape:\", clean.shape)\n","\n","\n","\n","data_report(clean)\n","\n","\n","\n","corr = clean.select_dtypes(include=[np.number]).corr(method=\"spearman\")\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(\n","    corr,\n","    annot=True,\n","    cmap=\"coolwarm\",\n","    center=0\n",")\n","plt.title(\"Spearman Correlation Matrix\")\n","plt.show()\n","\n"],"metadata":{"id":"RhMB6yWmjsYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":21,"metadata":{"id":"mamd7x8Be47r","executionInfo":{"status":"ok","timestamp":1765562741674,"user_tz":-120,"elapsed":9,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}}},"outputs":[],"source":["assert isinstance(raw, pd.DataFrame)\n","assert isinstance(clean, pd.DataFrame)\n","assert clean.isna().sum().sum() == 0\n","assert len(raw.columns) == len(clean.columns)\n","assert TO_PREDICT in raw.columns\n","assert TO_PREDICT in clean.columns"]},{"cell_type":"markdown","source":["# üî® Task 2 (1 point): Data transformation and preparation for training"],"metadata":{"id":"eFK3aoGrhOTc"}},{"cell_type":"markdown","source":["Next step is to prepare data for the model training. The DataFrame created during this task should be called `transformed`.\n","\n","1. (0.4p) Standardize numeric columns:\n","   - using the `scikit-learn` package;\n","   - using just `numpy`;\n","   - Compare results and show that they are the same or similar enough. If there is any difference, notice how big it is.\n","2. (0.3p) Encode all categorical columns except snail genus using one-hot encoding from `pandas` or `scikit-learn`. Make sure that in the end, there are N-1 columns for a categorical column with N unique values. Make sure that old categorical columns are not left in the data.\n","3. (0.2p) Encode the snail genus as integer column using `pandas` or `numpy`. Make sure to create a dictionary `snail_classes` mapping snail genera and integers.\n","4. (0.1p) Create `X` and `y` from the whole data. The `X` should contain all columns except the snail genus column, and the `y` should contain only the snail genus column and be a `Series` object."],"metadata":{"id":"dyc7OWgFhW6e"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","numeric_cols = clean.select_dtypes(include=[np.number]).columns\n","categorical_cols = clean.select_dtypes(exclude=[np.number]).columns.drop(TO_PREDICT)\n","\n","\n","scaler = StandardScaler()\n","scaled_sklearn = pd.DataFrame(\n","    scaler.fit_transform(clean[numeric_cols]),\n","    columns=numeric_cols,\n","    index=clean.index\n",")\n","\n","scaled_numpy = (clean[numeric_cols] - clean[numeric_cols].mean()) / clean[numeric_cols].std()\n","\n","diff = (scaled_sklearn - scaled_numpy).abs().max().max()\n","print(f\"Max difference between sklearn and numpy scaling: {diff:.6f}\")\n","\n","\n","encoded_cat = pd.get_dummies(\n","    clean[categorical_cols],\n","    drop_first=True\n",")\n","\n","\n","classes = sorted(clean[TO_PREDICT].unique())\n","snail_classes = {cls: idx for idx, cls in enumerate(classes)}\n","\n","encoded_target = clean[TO_PREDICT].map(snail_classes).astype(int)\n","\n","\n","transformed = pd.concat(\n","    [scaled_sklearn, encoded_cat],\n","    axis=1\n",")\n","\n","transformed[TO_PREDICT] = encoded_target\n","\n","\n","X = transformed.drop(columns=[TO_PREDICT])\n","y = transformed[TO_PREDICT]\n","\n","\n"],"metadata":{"id":"lrNa5BIHj4TO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765563162571,"user_tz":-120,"elapsed":34,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}},"outputId":"d7da3e03-f4da-4f67-a8a2-a9beded2ec69"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Max difference between sklearn and numpy scaling: 0.000551\n"]}]},{"cell_type":"code","source":["assert isinstance(transformed, pd.DataFrame)\n","assert transformed.isna().sum().sum() == 0\n","assert len(transformed.columns) > len(clean.columns)\n","assert TO_PREDICT in transformed.columns\n","assert transformed[TO_PREDICT].dtype == int\n","assert str not in transformed.dtypes  # CHECK IF WORKS\n","assert 2 in transformed[TO_PREDICT]\n","assert isinstance(X, pd.DataFrame)\n","assert len(X.columns) == len(transformed.columns) - 1\n","assert isinstance(y, pd.Series)\n","assert isinstance(snail_classes, dict)"],"metadata":{"id":"e-yDuzSij4L7","executionInfo":{"status":"ok","timestamp":1765563167672,"user_tz":-120,"elapsed":21,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["# üéì Task 3 (1 point): Model training and evaluation"],"metadata":{"id":"zy4IVj2yhXai"}},{"cell_type":"markdown","source":["Write a function named `split_and_train_model` which uses the standard model training pipeline:\n","- It should take `X`, `y`, `random_seed`, and a function (type `Callable`) to create the model. It should also take an optional `max_iter` parameter with default value of 300.\n","- Inside, it should:\n","   - Correctly split `X` and `y` into `X_train`, `y_train`, `X_test`, `y_test`. You can use different names but the structure should remain the same. Use test size of 20%. Use `random_seed` to fix the random state of data splitting.\n","   - Create an instance of the chosen model (by calling the provided function), with its random seed fixed to `random_seed` parameter.\n","   - Use the model to fit `X_train` and `y_train`.\n","   - Use the fitted model to generate predictions from `X_test`.\n","   - Calculate the accuracy score by comparing `y_test` and obtained predictions. Print out the score (formatted using f-string).\n","   - Return the trained model.\n","   - In case of **any** exception, do not raise it, but print out the error message and return `None` instead.\n","\n","As an usage example, use this function with the data prepared in Task 2 and `LogisticRegression` from `scikit-learn`."],"metadata":{"id":"RWgPK0cxhh68"}},{"cell_type":"code","source":["from typing import Callable\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","\n","def split_and_train_model(X, y, random_seed, model_fn: Callable, max_iter: int = 300):\n","    try:\n","        # 1) split\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            X, y,\n","            test_size=0.2,\n","            random_state=random_seed,\n","            stratify=y  # helps when classes are imbalanced\n","        )\n","\n","        # 2) create model (force random_state if supported)\n","        model = model_fn(random_state=random_seed, max_iter=max_iter)\n","\n","        # 3) fit\n","        model.fit(X_train, y_train)\n","\n","        # 4) predict + score\n","        preds = model.predict(X_test)\n","        acc = accuracy_score(y_test, preds)\n","        print(f\"Accuracy: {acc:.4f}\")\n","\n","        # 5) return trained model\n","        return model\n","\n","    except Exception as e:\n","        print(f\"Error while training model: {e}\")\n","        return None\n","\n","\n","logreg_model = split_and_train_model(\n","    X=X,\n","    y=y,\n","    random_seed=42,\n","    model_fn=lambda random_state, max_iter: LogisticRegression(\n","        random_state=random_state,\n","        max_iter=max_iter\n","    ),\n","    max_iter=300\n",")\n"],"metadata":{"id":"N1Kabl8WhUt4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765563260853,"user_tz":-120,"elapsed":400,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}},"outputId":"ba596459-295e-4a53-872d-e1d9a322fe84"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6923\n"]}]},{"cell_type":"code","source":["# no asserts there!"],"metadata":{"id":"kg7sLMD8o5wS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üß© Task 4 (2 points): Feature extraction - clustering"],"metadata":{"id":"jslHSd-Mhnk8"}},{"cell_type":"markdown","source":["Someone from SNAILAB theorized that knowing the genus of the plant which the leaf belongs to should help predict the genus of the snail, as certain snails are attracted to certain plants. However, the dataset does not contain plant names, and either way, plant identification requires additional time and skill.\n","\n","Instead, you can use unsupervised learning to cluster plant features and use this information as a new feature.\n","\n","1. (0.1p) Create a new DataFrame `plants` containing only plant features from `transformed`. Here, you are allowed to write column names manually.\n","2. (0.9p) You will use several clustering methods: [Affinity Propagation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html), [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html), [Spectral Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html), and [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans). They allow to provide different clustering parameters. Create a list `cluster_setups` containing `tuple[str, Callable, dict]` items (setups), where `str` is a short model name just for printing purposes, `Callable` is the clustering function (which you will call), and `dict` is a dictionary of 1-2 parameters to provide to that function.\n","   - There should be several setups for each clustering method. Use `for` loops to create those setups automatically by going through lists of possible parameters. You are allowed to write the lists manually or use `np.linspace` and similar functions:\n","      - For Affinity Propagation, use 2-3 different `damping` values between 0.6 and 0.9;\n","      - For Spectral Clustering and KMeans, use 4-5 `n_clusters` values between 3 and 20.\n","      - For DBSCAN, use 4-5 `eps` values between 0.1 and 0.5, and 4-5 `min_samples` values between 5 and 40 (so each DBSCAN setup had two provided parameters instead of one).\n","3. (1.0p) For each setup in `cluster_setups`, fit a clustering model on `plants` data and get the preidcted labels for all plants. Save the labels into a dictionary `obtained_clusters` which should be of type `dict[str, list]`, The `str` keys should be some kind of automatically generated short model descriptions (e.g. use f-string and include used parameter values in it). The `list` values should be lists of predicted cluster labels.\n","   - You may want to use `tqdm` at this point, as some clustering methods are slower."],"metadata":{"id":"I42INxTThxf4"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.cluster import AffinityPropagation, DBSCAN, SpectralClustering, KMeans\n","\n","# 1) plants = only plant features from transformed\n","# We treat \"leaf_*\" as plant-related features.\n","plant_cols = [c for c in transformed.columns if c.startswith(\"leaf_\")]\n","plants = transformed[plant_cols].copy()\n","\n","# 2) Create cluster_setups: list[tuple[str, Callable, dict]]\n","def run_affinity(data, **params):\n","    model = AffinityPropagation(**params)\n","    labels = model.fit_predict(data)\n","    return labels\n","\n","def run_dbscan(data, **params):\n","    model = DBSCAN(**params)\n","    labels = model.fit_predict(data)\n","    return labels\n","\n","def run_spectral(data, **params):\n","    # affinity='nearest_neighbors' is usually more stable than default 'rbf'\n","    model = SpectralClustering(affinity=\"nearest_neighbors\", **params)\n","    labels = model.fit_predict(data)\n","    return labels\n","\n","def run_kmeans(data, **params):\n","    model = KMeans(**params)\n","    labels = model.fit_predict(data)\n","    return labels\n","\n","cluster_setups = []\n","\n","# Affinity Propagation: 2-3 damping values between 0.6 and 0.9\n","for damping in [0.6, 0.75, 0.9]:\n","    name = f\"AffinityPropagation(damping={damping})\"\n","    cluster_setups.append((name, run_affinity, {\"damping\": damping}))\n","\n","# Spectral Clustering: 4-5 n_clusters values between 3 and 20\n","for n_clusters in [3, 5, 8, 12, 20]:\n","    name = f\"SpectralClustering(n_clusters={n_clusters})\"\n","    cluster_setups.append((name, run_spectral, {\"n_clusters\": n_clusters, \"random_state\": 42}))\n","\n","# KMeans: 4-5 n_clusters values between 3 and 20\n","for n_clusters in [3, 5, 8, 12, 20]:\n","    name = f\"KMeans(n_clusters={n_clusters})\"\n","    cluster_setups.append((name, run_kmeans, {\"n_clusters\": n_clusters, \"random_state\": 42, \"n_init\": 10}))\n","\n","# DBSCAN: 4-5 eps between 0.1 and 0.5 AND 4-5 min_samples between 5 and 40\n","eps_values = [0.1, 0.2, 0.3, 0.4, 0.5]\n","min_samples_values = [5, 10, 20, 40]\n","for eps in eps_values:\n","    for min_samples in min_samples_values:\n","        name = f\"DBSCAN(eps={eps},min_samples={min_samples})\"\n","        cluster_setups.append((name, run_dbscan, {\"eps\": eps, \"min_samples\": min_samples}))\n","\n","# 3) Fit each setup on plants and store labels\n","obtained_clusters = {}\n","plants_array = plants.to_numpy()\n","\n","for name, fn, params in cluster_setups:\n","    labels = fn(plants_array, **params)\n","    obtained_clusters[name] = list(labels)\n","\n","print(f\"Plants shape: {plants.shape}\")\n","print(f\"Number of clustering setups: {len(cluster_setups)}\")\n"],"metadata":{"id":"B7fvuZXGhy1R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765563442396,"user_tz":-120,"elapsed":38579,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}},"outputId":"018a54ed-2649-4f13-bad9-9820963469b7"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Plants shape: (2596, 4)\n","Number of clustering setups: 33\n"]}]},{"cell_type":"code","source":["assert isinstance(plants, pd.DataFrame)\n","assert isinstance(cluster_setups, list)\n","assert isinstance(obtained_clusters, dict)\n","assert len(cluster_setups) == len(obtained_clusters)\n","assert len(cluster_setups) >= 26"],"metadata":{"id":"pTzjEaMoqz3H","executionInfo":{"status":"ok","timestamp":1765563456072,"user_tz":-120,"elapsed":6,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# üëë Task 5 (2 points): Using extracted features to improve the result"],"metadata":{"id":"5uKxDGaZxb0D"}},{"cell_type":"markdown","source":["The only thing left now is to check which clustering setup produced a new feature (predicted plant clusters) which improves the Logistic Regression model trained in Task 3.\n","\n","1. (1.0p) For each plant clustering result from Task 4, check if it improves the accuracy of logistic regression:\n","   - Create a new variable `XX` containing the `X` from Task 2 but joined with the new feature. If the shape of `X` was (M, N), then the shape of `XX` should be (M, N+1).\n","   - Using already written `split_and_train_model` function, create and fit a new logistic regression model on `XX` (`y` remains unchanged from Task 2). You may need to increase `max_iter` here. Don't forget to use the same random seed for all models.\n","2. (1.0p) Automatically find the feature which produced the best result from all trained Logistic Regression models. Print out its name and received accuracy score.\n"],"metadata":{"id":"xuAg6E1bqzuC"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","RANDOM_SEED = 42\n","\n","# Baseline (no extra cluster feature) accuracy\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",")\n","\n","baseline_model = LogisticRegression(random_state=RANDOM_SEED, max_iter=1000)\n","baseline_model.fit(X_train, y_train)\n","baseline_preds = baseline_model.predict(X_test)\n","baseline_acc = accuracy_score(y_test, baseline_preds)\n","\n","print(f\"Baseline LogisticRegression accuracy (no clusters): {baseline_acc:.4f}\")\n","\n","best_name = None\n","best_acc = baseline_acc\n","best_model = baseline_model\n","\n","results = []\n","\n","for name, labels in obtained_clusters.items():\n","    # 1) make XX = X joined with 1 new feature column\n","    cluster_feature = pd.Series(labels, index=X.index, name=\"plant_cluster\")\n","\n","    XX = X.join(cluster_feature)\n","\n","    # sanity check shape: (M, N+1)\n","    if XX.shape[1] != X.shape[1] + 1:\n","        print(f\"Skipping {name}: shape mismatch {XX.shape} vs expected (M, N+1)\")\n","        continue\n","\n","    # 2) train/evaluate with same split\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        XX, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n","    )\n","\n","    model = LogisticRegression(random_state=RANDOM_SEED, max_iter=2000)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_test)\n","    acc = accuracy_score(y_test, preds)\n","\n","    results.append((name, acc))\n","\n","    # also run the required function (prints score + returns model)\n","    _ = split_and_train_model(\n","        XX, y, RANDOM_SEED,\n","        model_fn=lambda random_state, max_iter: LogisticRegression(random_state=random_state, max_iter=max_iter),\n","        max_iter=2000\n","    )\n","\n","    if acc > best_acc:\n","        best_acc = acc\n","        best_name = name\n","        best_model = model\n","\n","# 3) report best\n","results_sorted = sorted(results, key=lambda x: x[1], reverse=True)\n","\n","print(\"\\nTop 10 clustering features by accuracy:\")\n","for n, a in results_sorted[:10]:\n","    print(f\"{n}: {a:.4f}\")\n","\n","if best_name is None:\n","    print(f\"\\nNo clustering feature improved the baseline. Best remains baseline: {baseline_acc:.4f}\")\n","else:\n","    print(f\"\\n Best clustering feature: {best_name}\")\n","    print(f\" Best accuracy: {best_acc:.4f} (baseline was {baseline_acc:.4f})\")\n"],"metadata":{"id":"EhJD1ZihyCob","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765563660254,"user_tz":-120,"elapsed":28377,"user":{"displayName":"Mykolas Stankeviƒçius","userId":"03303782963928623537"}},"outputId":"fc97a09c-9145-4edb-9190-d938e7bd802c"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline LogisticRegression accuracy (no clusters): 0.6923\n","Accuracy: 0.7462\n","Accuracy: 0.7500\n","Accuracy: 0.7500\n","Accuracy: 0.7288\n","Accuracy: 0.7596\n","Accuracy: 0.7750\n","Accuracy: 0.7385\n","Accuracy: 0.7558\n","Accuracy: 0.7327\n","Accuracy: 0.7615\n","Accuracy: 0.7192\n","Accuracy: 0.8000\n","Accuracy: 0.7712\n","Accuracy: 0.7346\n","Accuracy: 0.7192\n","Accuracy: 0.7269\n","Accuracy: 0.6962\n","Accuracy: 0.7962\n","Accuracy: 0.7673\n","Accuracy: 0.7308\n","Accuracy: 0.7577\n","Accuracy: 0.7635\n","Accuracy: 0.7558\n","Accuracy: 0.7962\n","Accuracy: 0.7865\n","Accuracy: 0.7269\n","Accuracy: 0.7269\n","Accuracy: 0.7654\n","Accuracy: 0.7538\n","Accuracy: 0.7269\n","Accuracy: 0.7269\n","Accuracy: 0.7500\n","Accuracy: 0.7596\n","\n","Top 10 clustering features by accuracy:\n","KMeans(n_clusters=12): 0.8000\n","DBSCAN(eps=0.2,min_samples=5): 0.7962\n","DBSCAN(eps=0.3,min_samples=20): 0.7962\n","DBSCAN(eps=0.3,min_samples=40): 0.7865\n","SpectralClustering(n_clusters=8): 0.7750\n","KMeans(n_clusters=20): 0.7712\n","DBSCAN(eps=0.2,min_samples=10): 0.7673\n","DBSCAN(eps=0.4,min_samples=20): 0.7654\n","DBSCAN(eps=0.3,min_samples=5): 0.7635\n","KMeans(n_clusters=5): 0.7615\n","\n"," Best clustering feature: KMeans(n_clusters=12)\n"," Best accuracy: 0.8000 (baseline was 0.6923)\n"]}]},{"cell_type":"code","source":["# no asserts again!"],"metadata":{"id":"JTPjKei9yD3c"},"execution_count":null,"outputs":[]}]}